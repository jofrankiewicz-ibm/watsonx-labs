{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zaawansowany Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Witaj w drugiej części laboratorium poświęconemu prompt engineeringowi. Tym razem będziemy odpytywać watsonx.ai z poziomu kodu przygotowanego w Pythonie. \n",
    "\n",
    "Upewnij się, że przed wykonaniem ćwiczenia przygotowałeś środowisko zgodnie z instrukcją.\n",
    "\n",
    "Ćwiczenie powinno zająć Ci ok. 30/40 minut\n",
    "\n",
    "Powodzenia!\n",
    "Pamiętaj o porównaniu swoich rezultatów z przygotowanymi przez nas odpowiedziami.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Załaduj niezbędne biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from dotenv import load_dotenv\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Załaduj swoje credentiale do środowiska Watsonx.ai\n",
    "    - Aby uzyskać api_key, zaloguj się do swojego konta na IBM Cloud, następnie w zakładce Manage wybierz Access (IAM), po lewej stronie na liście pojawi się sekcja API Keys, w której należy wygenerować nowy API key. Wygenerowany klucz następnie należy skopiować i uzupełnić nim pole api_key poniżej.\n",
    "\n",
    "    - Jako endpoint, użyj \"https://us-south.ml.cloud.ibm.com\".\n",
    "\n",
    "    - Aby uzyskać projekt_id, wejdź w nazwę swojego projektu, następnie w zakładkę Manage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name\n",
    "#google/flan-ul2\n",
    "#google/flan-t5-xxl\n",
    "#ibm/mpt-7b-instruct2\n",
    "#EleutherAI/gpt-neox-20b\n",
    "\n",
    "#decoding_method\n",
    "#greedy\n",
    "#sampling\n",
    "\n",
    "#Skonfiguruj środowisko watsonx.ai\n",
    "my_credentials = {\n",
    "    \"url\" : \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\" : \"\"\n",
    "}\n",
    "project_id = \"\"\n",
    "\n",
    "def send_to_watsonxai(prompt,\n",
    "                    model_id=ModelTypes.FLAN_UL2,\n",
    "                    decoding_method=\"greedy\",\n",
    "                    max_new_tokens=100, #maximum value - 500\n",
    "                    min_new_tokens=30, #minimum value - 0\n",
    "                    temperature=1.0,\n",
    "                    repetition_penalty=2.0\n",
    "                    ):\n",
    "    '''\n",
    "   helper function for sending prompts and params to Watsonx.ai\n",
    "    \n",
    "    Args:  \n",
    "        prompts:list list of text prompts\n",
    "        decoding:str Watsonx.ai parameter \"sample\" or \"greedy\"\n",
    "        max_new_tok:int Watsonx.ai parameter for max new tokens/response returned\n",
    "        temp:float Watsonx.ai parameter for temperature (range 0>2)\n",
    "\n",
    "    Returns: None\n",
    "        prints response\n",
    "    '''\n",
    "\n",
    "    space_id = None\n",
    "    verify = False\n",
    "    \n",
    "    generate_params = {\n",
    "        GenParams.DECODING_METHOD: decoding_method,\n",
    "        GenParams.MAX_NEW_TOKENS: max_new_tokens,\n",
    "        GenParams.MIN_NEW_TOKENS: min_new_tokens,\n",
    "        GenParams.TEMPERATURE: temperature,\n",
    "        GenParams.REPETITION_PENALTY: repetition_penalty,\n",
    "        GenParams.RANDOM_SEED: 42\n",
    "    }\n",
    "\n",
    "    # Instantiate a model proxy object to send your requests\n",
    "    model = Model( model_id, my_credentials, generate_params, project_id, space_id, verify )   \n",
    "\n",
    "    result = model.generate(prompt)\n",
    "    print(result[\"results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 1) Poziom a1c pacjenta określa jego status cukrzycowy, zasady są następujące:\n",
    "\n",
    " - mniej niż 5.7 oznacza brak cukrzycy\n",
    " - pomiędzy 5.7 a 6.5 stan przedcukrzycowy\n",
    " - więcej niż 6.5 oznacza stan cukrzycowy.\n",
    "\n",
    "Na podstawie poniższych trzech przykładów, napisz prompt który zwróci status cukrzycowy opisanych przypadków:\n",
    "\n",
    "1)\tThe patients a1c is 5.5 which is good considering his other risk factors.\n",
    "2)\tFrom the last lab report I noted the A1c is 6.4 so we need to put her on Ozempic.\n",
    "3)\tShe mentioned her A1c is 8 according to her blood work about 3 years ago.\n",
    "\n",
    "Bonus 1: Jak możesz poprawić wnioskowanie, biorąc pod uwagę inne informacje w zdaniach?\n",
    "\n",
    "Bonus 2: jak podszedłbyś do wyodrębnienia statusu cukrzycy na podstawie notatek pacjenta bez wartości A1C i na co musiałbyś uważać? (wskazówka: może mówią o historii choroby w rodzinie lub innych komplikacjach)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'diabetic.nThe patients a1c is 5.5 which is good considering his other risk factors.nFrom the last lab report I noted the A1c is 6.4 so we need to put her on Ozempic.nShe mentioned her A1c is 8 according to her blood work about 3 years ago.n', 'generated_token_count': 74, 'input_token_count': 135, 'stop_reason': 'EOS_TOKEN'}]\n"
     ]
    }
   ],
   "source": [
    "#Q1 ENTER YOUR MODEL PARAMS HERE - MAKE SURE IT WORKS WITH ALL 3 EXAMPLES ABOVE\n",
    "\n",
    "\n",
    "prompt = \"\"\n",
    "\n",
    "\n",
    "\n",
    "response = send_to_watsonxai(prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opinia produktu dla zadań 2-6\n",
    " = \"\"\"Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 2) Napisz prompt, który zwróci sentyment związany z podaną opinią\n",
    "Target sentiment = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "#Q2 Code - enter prompt and parameters in this cell\n",
    "prompt = \n",
    "response = send_to_watsonxai(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 3) wydobądź emocje jakie wyraża recenzent, zwróć odpowiedzi w postaci listy, oddzielonej przecinkami\n",
    "Target emotions = satisfied, happy, cared for, great company, product!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfied, happy, cared for, great company, product!. '''r\n"
     ]
    }
   ],
   "source": [
    "prompt = \n",
    "response = send_to_watsonxai(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 4) Czy recenzent przejawia złośći? Odpowiedz w postaci tak lub nie.\n",
    "Target answer = no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "prompt =\n",
    "response = send_to_watsonxai(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 5) Wyodrębnij zakupiony przedmiot i nazwę firmy, zwróć w formacie JSON\n",
    "Target answer = Item[lamp], Brand[Lumina]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item[lamp], Brand[Lumina]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "Review text: '''{review}'''\n",
    "\"\"\"\n",
    "\n",
    "prompt = \n",
    "response = send_to_watsonxai(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 6) Czy możesz połączyć 3-6 przykładów w jednym prompcie i zwrócić JSON z: Nastrojem (negatywnym lub pozytywnym), Gniewem (tak/nie), Produktem, Firmą\n",
    "Target answer = Sentiment[positive], Anger[false], Item[lamp], Brand[Lumina]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment[positive], Anger[false], Item[lamp], Brand[Lumina]\n"
     ]
    }
   ],
   "source": [
    "prompt = \n",
    "response = send_to_watsonxai(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 7) Podsumuj poniższą recenzję produktu\n",
    "Example summary = My daughter loves it!  It's soft and  super cute, and its face has a friendly look. It's  a bit small for what I paid though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\ \n",
    "super cute, and its face has a friendly look. It's \\ \n",
    "a bit small for what I paid though. I think there \\ \n",
    "might be other options that are bigger for the \\ \n",
    "same price. It arrived a day earlier than expected, \\ \n",
    "so I got to play with it myself before I gave it to her.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My daughter loves it!  It's soft and  super cute, and its face has a friendly look. It's  a bit small for what I paid though.\n"
     ]
    }
   ],
   "source": [
    "prompt =\n",
    "response = send_to_watsonxai(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 8) Podsumuj tę samą recenzję produktu z perspektywy działu spedycji\n",
    "Example summary = It arrived a day earlier than expected, so I got to play with it myself before I gave it  to her. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It arrived a day earlier than expected,  so I got to play with it myself before I gave it  to her. \n"
     ]
    }
   ],
   "source": [
    "#concise wrt feedback shipping\n",
    "prompt = \n",
    "response = send_to_watsonxai(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 9)Podsumuj tę samą recenzję produktu z perspektywy ceny i wartości\n",
    "Example summary = It's a bit small for what I paid though. I think there might be other options that are bigger for the same price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a bit small for what I paid though. I think there  might be other options that are bigger for the  same price\n"
     ]
    }
   ],
   "source": [
    "#feedback pricing works - concise\n",
    "prompt = \n",
    "response = send_to_watsonxai(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10) Usunięcie informacji umożliwiających identyfikację. Biorąc pod uwagę następujący e-mail, napisz prompt o usunięcie informacji umożliwiających identyfikację (np. nazwiska, adresy e-mail itp.) (Wskazówka: może być konieczne użycie techniki one/two shot prompting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"\"\"\n",
    "Hi John,\\\n",
    "\n",
    "I'm writing to you because I noticed you recently purchased a new car. I'm a salesperson\\\n",
    "at a local dealership (Cheap Dealz), and I wanted to let you know that we have a great deal on a new\\\n",
    "car. If you're interested, please let me know.\\\n",
    "\n",
    "Thanks,\\\n",
    "\n",
    "Jimmy Smith\\\n",
    "\n",
    "Phone: 410-805-2345\\\n",
    "Email: jimmysmith@cheapdealz.com\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint - use prompt template or manually construct the prompt with f strings (look up in documentation if unsure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \n",
    "response = send_to_watsonxai(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
